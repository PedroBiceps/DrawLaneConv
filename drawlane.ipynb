{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "imageio.ffmpeg.download() has been deprecated. Use 'pip install imageio-ffmpeg' instead.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b633ff869ac2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimresize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meditor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programky\\Anaconda\\lib\\site-packages\\moviepy\\editor.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# Checks to see if the user has set a place for their own version of ffmpeg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FFMPEG_BINARY'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ffmpeg-imageio'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'ffmpeg-imageio'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mimageio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mffmpeg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# Clips\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programky\\Anaconda\\lib\\site-packages\\imageio\\plugins\\ffmpeg.pyc\u001b[0m in \u001b[0;36mdownload\u001b[1;34m(directory, force_download)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mISWIN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"win\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m FNAME_PER_PLATFORM = {\n\u001b[0;32m     42\u001b[0m     \u001b[1;34m\"osx32\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"ffmpeg-osx-v3.2.4\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: imageio.ffmpeg.download() has been deprecated. Use 'pip install imageio-ffmpeg' instead.'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.misc import imresize\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "# Load Keras model\n",
    "model = load_model('full_CNN_model.h5')\n",
    "\n",
    "# Class to average lanes with\n",
    "class Lanes():\n",
    "    def __init__(self):\n",
    "        self.recent_fit = []\n",
    "        self.avg_fit = []\n",
    "\n",
    "def road_lines(image):\n",
    "    \"\"\" Takes in a road image, re-sizes for the model,\n",
    "    predicts the lane to be drawn from the model in G color,\n",
    "    recreates an RGB image of a lane and merges with the\n",
    "    original road image.\n",
    "    \"\"\"\n",
    "\n",
    "    ysize = image.shape[0]\n",
    "    xsize = image.shape[1]\n",
    "    \n",
    "    # 1. Distortion correction\n",
    "    #undist = undistort(img, mtx, dist)\n",
    "    \n",
    "    # 2. Perspective transformation\n",
    "    src = np.float32([\n",
    "        (850,300),    \n",
    "        (350,300), \n",
    "        (40,700),  \n",
    "        (1160,700)\n",
    "    ])\n",
    "\n",
    "    dst = np.float32([\n",
    "        (xsize - 350, 0),\n",
    "        (350, 0),\n",
    "        (350, ysize),\n",
    "        (xsize - 350, ysize)\n",
    "    ])\n",
    "    \n",
    "    vertices = np.array([\n",
    "        [200, ysize],\n",
    "        [200, 0],\n",
    "        [1100, 0],\n",
    "        [1100, ysize]\n",
    "    ])\n",
    "\n",
    "    #roi = get_roi(warped, vertices)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Get image ready for feeding into model\n",
    "    image = warp_image(image, (xsize, ysize), src, dst)\n",
    "    image = get_roi(image, vertices)\n",
    "    global prank\n",
    "    prank = image\n",
    "    \n",
    "    small_img = imresize(image, (80, 160, 3))\n",
    "    small_img = np.array(small_img)\n",
    "    small_img = small_img[None,:,:,:]\n",
    "    \n",
    "    print(small_img.shape)\n",
    "\n",
    "    # Make prediction with neural network (un-normalize value by multiplying by 255)\n",
    "    prediction = model.predict(small_img)[0] * 255\n",
    "\n",
    "    # Add lane prediction to list for averaging\n",
    "    lanes.recent_fit.append(prediction)\n",
    "    # Only using last five for average\n",
    "    if len(lanes.recent_fit) > 5:\n",
    "        lanes.recent_fit = lanes.recent_fit[1:]\n",
    "\n",
    "    # Calculate average detection\n",
    "    lanes.avg_fit = np.mean(np.array([i for i in lanes.recent_fit]), axis = 0)\n",
    "\n",
    "    # Generate fake R & B color dimensions, stack with G\n",
    "    blanks = np.zeros_like(lanes.avg_fit).astype(np.uint8)\n",
    "    lane_drawn = np.dstack((blanks, lanes.avg_fit, blanks))\n",
    "\n",
    "    # Re-size to match the original image\n",
    "    lane_image = imresize(lane_drawn, (720, 1280, 3))\n",
    "\n",
    "    # Merge the lane drawing onto the original image\n",
    "    result = cv2.addWeighted(image, 1, lane_image, 1, 0)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def warp_image(img, warp_shape, src, dst):\n",
    "    '''\n",
    "    Performs perspective transformation (PT)\n",
    "    :param img (ndarray): Image\n",
    "    :param warp_shape: Shape of the warped image\n",
    "    :param src (ndarray): Source points\n",
    "    :param dst (ndarray): Destination points\n",
    "    :return : Tuple (Transformed image, PT matrix, PT inverse matrix)\n",
    "    '''\n",
    "    \n",
    "    # Get the perspective transformation matrix and its inverse\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    invM = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    # Warp the image\n",
    "    warped = cv2.warpPerspective(img, M, warp_shape, flags=cv2.INTER_LINEAR)\n",
    "    return warped\n",
    "\n",
    "\n",
    "def get_roi(img, vertices):\n",
    "    '''\n",
    "    Transforms an image by preserving only the ROI represented by the\n",
    "    the 'vertices' and removes the remainder of the image by setting the pixel intensity to 0\n",
    "    :param img (ndarray): Image\n",
    "    :param vertices (ndarray): Region of Interest of the image\n",
    "    :return : Modified image\n",
    "    '''\n",
    "    \n",
    "    vertices = np.array(vertices, ndmin=3, dtype=np.int32)\n",
    "    if len(img.shape) == 3:\n",
    "        fill_color = (255,) * 3\n",
    "    else:\n",
    "        fill_color = 255\n",
    "            \n",
    "    mask = np.zeros_like(img)\n",
    "    mask = cv2.fillPoly(mask, vertices, fill_color)\n",
    "    return cv2.bitwise_and(img, mask)\n",
    "\n",
    "\n",
    "\n",
    "lanes = Lanes()\n",
    "\n",
    "# Where to save the output video\n",
    "vid_output = 'proj_reg_vid.mp4'\n",
    "\n",
    "# Location of the input video\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "\n",
    "vid_clip = clip1.fl_image(road_lines)\n",
    "print(type(vid_clip))\n",
    "vid_clip.write_videofile(vid_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "imageio.ffmpeg.download() has been deprecated. Use 'pip install imageio-ffmpeg' instead.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-07956a6514f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimresize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meditor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programky\\Anaconda\\lib\\site-packages\\moviepy\\editor.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# Checks to see if the user has set a place for their own version of ffmpeg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FFMPEG_BINARY'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ffmpeg-imageio'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'ffmpeg-imageio'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mimageio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mffmpeg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# Clips\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programky\\Anaconda\\lib\\site-packages\\imageio\\plugins\\ffmpeg.pyc\u001b[0m in \u001b[0;36mdownload\u001b[1;34m(directory, force_download)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     raise RuntimeError(\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[1;34m\"imageio.ffmpeg.download() has been deprecated. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[1;34m\"Use 'pip install imageio-ffmpeg' instead.'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: imageio.ffmpeg.download() has been deprecated. Use 'pip install imageio-ffmpeg' instead.'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.misc import imresize\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load Keras model\n",
    "model = load_model('full_CNN_model.h5')\n",
    "\n",
    "# Class to average lanes with\n",
    "class Lanes():\n",
    "    def __init__(self):\n",
    "        self.recent_fit = []\n",
    "        self.avg_fit = []\n",
    "\n",
    "def road_lines(image):\n",
    "    \"\"\" Takes in a road image, re-sizes for the model,\n",
    "    predicts the lane to be drawn from the model in G color,\n",
    "    recreates an RGB image of a lane and merges with the\n",
    "    original road image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get image ready for feeding into model\n",
    "    small_img = imresize(image, (80, 160, 3))\n",
    "    small_img = np.array(small_img)\n",
    "    small_img = small_img[None,:,:,:]\n",
    "\n",
    "    # Make prediction with neural network (un-normalize value by multiplying by 255)\n",
    "    prediction = model.predict(small_img)[0] * 255\n",
    "\n",
    "    # Add lane prediction to list for averaging\n",
    "    lanes.recent_fit.append(prediction)\n",
    "    # Only using last five for average\n",
    "    if len(lanes.recent_fit) > 5:\n",
    "        lanes.recent_fit = lanes.recent_fit[1:]\n",
    "\n",
    "    # Calculate average detection\n",
    "    lanes.avg_fit = np.mean(np.array([i for i in lanes.recent_fit]), axis = 0)\n",
    "\n",
    "    # Generate fake R & B color dimensions, stack with G\n",
    "    blanks = np.zeros_like(lanes.avg_fit).astype(np.uint8)\n",
    "    lane_drawn = np.dstack((blanks, lanes.avg_fit, blanks))\n",
    "\n",
    "    # Re-size to match the original image\n",
    "    lane_image = imresize(lane_drawn, (720, 1280, 3))\n",
    "\n",
    "    # Merge the lane drawing onto the original image\n",
    "    result = cv2.addWeighted(image, 1, lane_image, 1, 0)\n",
    "\n",
    "    return result\n",
    "\n",
    "lanes = Lanes()\n",
    "\n",
    "# Where to save the output video\n",
    "vid_output = 'proj_reg_vid.mp4'\n",
    "\n",
    "# Location of the input video\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "\n",
    "vid_clip = clip1.fl_image(road_lines)\n",
    "vid_clip.write_videofile(vid_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
